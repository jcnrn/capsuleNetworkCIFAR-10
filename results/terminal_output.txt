
conranj@u-14:~/cifarcaps$ python capsulenet.py --routings 3
Using TensorFlow backend.
Namespace(batch_size=100, debug=False, digit=5, epochs=50, lam_recon=0.392, lr=0.001, lr_decay=1.0, routings=3, save_dir='./result', shift_fraction=0.1, testing=False, weights=None)
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 9, 9, 256)    442624      input_1[0][0]
__________________________________________________________________________________________________
primarycap_conv2d (Conv2D)      (None, 1, 1, 2048)   42469376    conv1[0][0]
__________________________________________________________________________________________________
primarycap_reshape (Reshape)    (None, 32, 64)       0           primarycap_conv2d[0][0]
__________________________________________________________________________________________________
primarycap_squash (Lambda)      (None, 32, 64)       0           primarycap_reshape[0][0]
__________________________________________________________________________________________________
digitcaps (CapsuleLayer)        (None, 10, 16)       327680      primarycap_squash[0][0]
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 10)           0
__________________________________________________________________________________________________
mask_1 (Mask)                   (None, 160)          0           digitcaps[0][0]
                                                                 input_2[0][0]
__________________________________________________________________________________________________
capsnet (Length)                (None, 10)           0           digitcaps[0][0]
__________________________________________________________________________________________________
decoder (Sequential)            (None, 32, 32, 3)    3756544     mask_1[0][0]
==================================================================================================
Total params: 46,996,224
Trainable params: 46,996,224
Non-trainable params: 0
__________________________________________________________________________________________________
2017-12-07 21:33:49.195937: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-12-07 21:33:51.533045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-12-07 21:33:51.533780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2017-12-07 21:33:51.533805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
499/500 [============================>.] - ETA: 0s - loss: 0.5017 - capsnet_loss                                                                                                                               500/500 [==============================] - 52s 103ms/step - loss: 0.5016 - capsn                                                                                                                               et_loss: 0.4792 - decoder_loss: 0.0570 - capsnet_acc: 0.2300 - val_loss: 0.4473                                                                                                                                - val_capsnet_loss: 0.4265 - val_decoder_loss: 0.0531 - val_capsnet_acc: 0.3370
Epoch 2/50
499/500 [============================>.] - ETA: 0s - loss: 0.4359 - capsnet_loss                                                                                                                               500/500 [==============================] - 51s 102ms/step - loss: 0.4359 - capsn                                                                                                                               et_loss: 0.4161 - decoder_loss: 0.0505 - capsnet_acc: 0.3567 - val_loss: 0.4088                                                                                                                                - val_capsnet_loss: 0.3904 - val_decoder_loss: 0.0469 - val_capsnet_acc: 0.4068
Epoch 3/50
499/500 [============================>.] - ETA: 0s - loss: 0.4129 - capsnet_loss                                                                                                                               500/500 [==============================] - 51s 102ms/step - loss: 0.4129 - capsn                                                                                                                               et_loss: 0.3950 - decoder_loss: 0.0456 - capsnet_acc: 0.3981 - val_loss: 0.3886                                                                                                                                - val_capsnet_loss: 0.3721 - val_decoder_loss: 0.0421 - val_capsnet_acc: 0.4346
Epoch 4/50
499/500 [============================>.] - ETA: 0s - loss: 0.3987 - capsnet_loss: 0.3822 - decoder_loss: 0.0421 - capsnet_acc: 0.4188Epoch 00004: val_capsnet_acc improved from 0.43460 to 0.45290, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.3986 - capsnet_loss: 0.3821 - decoder_loss: 0.0421 - capsnet_acc: 0.4188 - val_loss: 0.3770 - val_capsnet_loss: 0.3613 - val_decoder_loss: 0.0400 - val_capsnet_acc: 0.4529
Epoch 5/50
499/500 [============================>.] - ETA: 0s - loss: 0.3869 - capsnet_loss: 0.3710 - decoder_loss: 0.0405 - capsnet_acc: 0.4367Epoch 00005: val_capsnet_acc improved from 0.45290 to 0.46950, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3869 - capsnet_loss: 0.3710 - decoder_loss: 0.0405 - capsnet_acc: 0.4367 - val_loss: 0.3677 - val_capsnet_loss: 0.3525 - val_decoder_loss: 0.0389 - val_capsnet_acc: 0.4695
Epoch 6/50
499/500 [============================>.] - ETA: 0s - loss: 0.3779 - capsnet_loss: 0.3624 - decoder_loss: 0.0394 - capsnet_acc: 0.4518Epoch 00006: val_capsnet_acc improved from 0.46950 to 0.47300, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3779 - capsnet_loss: 0.3625 - decoder_loss: 0.0394 - capsnet_acc: 0.4517 - val_loss: 0.3633 - val_capsnet_loss: 0.3480 - val_decoder_loss: 0.0390 - val_capsnet_acc: 0.4730
Epoch 7/50
499/500 [============================>.] - ETA: 0s - loss: 0.3696 - capsnet_loss: 0.3545 - decoder_loss: 0.0385 - capsnet_acc: 0.4636Epoch 00007: val_capsnet_acc improved from 0.47300 to 0.48770, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3695 - capsnet_loss: 0.3544 - decoder_loss: 0.0385 - capsnet_acc: 0.4637 - val_loss: 0.3531 - val_capsnet_loss: 0.3383 - val_decoder_loss: 0.0377 - val_capsnet_acc: 0.4877
Epoch 8/50
499/500 [============================>.] - ETA: 0s - loss: 0.3628 - capsnet_loss: 0.3480 - decoder_loss: 0.0378 - capsnet_acc: 0.4736Epoch 00008: val_capsnet_acc improved from 0.48770 to 0.48910, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.3628 - capsnet_loss: 0.3480 - decoder_loss: 0.0378 - capsnet_acc: 0.4736 - val_loss: 0.3508 - val_capsnet_loss: 0.3362 - val_decoder_loss: 0.0370 - val_capsnet_acc: 0.4891
Epoch 9/50
499/500 [============================>.] - ETA: 0s - loss: 0.3562 - capsnet_loss: 0.3418 - decoder_loss: 0.0369 - capsnet_acc: 0.4852Epoch 00009: val_capsnet_acc improved from 0.48910 to 0.50150, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.3563 - capsnet_loss: 0.3418 - decoder_loss: 0.0369 - capsnet_acc: 0.4851 - val_loss: 0.3488 - val_capsnet_loss: 0.3344 - val_decoder_loss: 0.0367 - val_capsnet_acc: 0.5015
Epoch 10/50
499/500 [============================>.] - ETA: 0s - loss: 0.3509 - capsnet_loss: 0.3367 - decoder_loss: 0.0362 - capsnet_acc: 0.4934Epoch 00010: val_capsnet_acc improved from 0.50150 to 0.51550, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3510 - capsnet_loss: 0.3368 - decoder_loss: 0.0362 - capsnet_acc: 0.4932 - val_loss: 0.3392 - val_capsnet_loss: 0.3249 - val_decoder_loss: 0.0364 - val_capsnet_acc: 0.5155
Epoch 11/50
499/500 [============================>.] - ETA: 0s - loss: 0.3462 - capsnet_loss: 0.3321 - decoder_loss: 0.0358 - capsnet_acc: 0.5044Epoch 00011: val_capsnet_acc improved from 0.51550 to 0.52550, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3461 - capsnet_loss: 0.3321 - decoder_loss: 0.0358 - capsnet_acc: 0.5044 - val_loss: 0.3341 - val_capsnet_loss: 0.3203 - val_decoder_loss: 0.0351 - val_capsnet_acc: 0.5255
Epoch 12/50
500/500 [==============================] - 51s 101ms/step - loss: 0.3398 - capsnet_loss: 0.3260 - decoder_loss: 0.0352 - capsnet_acc: 0.5158 - val_loss: 0.3325 - val_capsnet_loss: 0.3189 - val_decoder_loss: 0.0349 - val_capsnet_acc: 0.5252
Epoch 13/50
499/500 [============================>.] - ETA: 0s - loss: 0.3363 - capsnet_loss: 0.3227 - decoder_loss: 0.0349 - capsnet_acc: 0.5191Epoch 00013: val_capsnet_acc improved from 0.52550 to 0.53530, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.3363 - capsnet_loss: 0.3226 - decoder_loss: 0.0349 - capsnet_acc: 0.5192 - val_loss: 0.3267 - val_capsnet_loss: 0.3133 - val_decoder_loss: 0.0343 - val_capsnet_acc: 0.5353
Epoch 14/50
499/500 [============================>.] - ETA: 0s - loss: 0.3320 - capsnet_loss: 0.3185 - decoder_loss: 0.0344 - capsnet_acc: 0.5278Epoch 00014: val_capsnet_acc improved from 0.53530 to 0.53650, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3319 - capsnet_loss: 0.3185 - decoder_loss: 0.0344 - capsnet_acc: 0.5278 - val_loss: 0.3250 - val_capsnet_loss: 0.3117 - val_decoder_loss: 0.0341 - val_capsnet_acc: 0.5365
Epoch 15/50
499/500 [============================>.] - ETA: 0s - loss: 0.3292 - capsnet_loss: 0.3159 - decoder_loss: 0.0339 - capsnet_acc: 0.5301Epoch 00015: val_capsnet_acc improved from 0.53650 to 0.54240, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.3293 - capsnet_loss: 0.3160 - decoder_loss: 0.0339 - capsnet_acc: 0.5299 - val_loss: 0.3220 - val_capsnet_loss: 0.3089 - val_decoder_loss: 0.0336 - val_capsnet_acc: 0.5424
Epoch 16/50
499/500 [============================>.] - ETA: 0s - loss: 0.3261 - capsnet_loss: 0.3130 - decoder_loss: 0.0335 - capsnet_acc: 0.5328Epoch 00016: val_capsnet_acc improved from 0.54240 to 0.54670, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.3261 - capsnet_loss: 0.3130 - decoder_loss: 0.0335 - capsnet_acc: 0.5327 - val_loss: 0.3213 - val_capsnet_loss: 0.3083 - val_decoder_loss: 0.0332 - val_capsnet_acc: 0.5467
Epoch 17/50
499/500 [============================>.] - ETA: 0s - loss: 0.3223 - capsnet_loss: 0.3093 - decoder_loss: 0.0331 - capsnet_acc: 0.5423Epoch 00017: val_capsnet_acc improved from 0.54670 to 0.55120, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.3223 - capsnet_loss: 0.3093 - decoder_loss: 0.0331 - capsnet_acc: 0.5422 - val_loss: 0.3173 - val_capsnet_loss: 0.3044 - val_decoder_loss: 0.0329 - val_capsnet_acc: 0.5512
Epoch 18/50
499/500 [============================>.] - ETA: 0s - loss: 0.3201 - capsnet_loss: 0.3072 - decoder_loss: 0.0328 - capsnet_acc: 0.5462Epoch 00018: val_capsnet_acc improved from 0.55120 to 0.55200, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3200 - capsnet_loss: 0.3072 - decoder_loss: 0.0328 - capsnet_acc: 0.5464 - val_loss: 0.3161 - val_capsnet_loss: 0.3033 - val_decoder_loss: 0.0325 - val_capsnet_acc: 0.5520
Epoch 19/50
499/500 [============================>.] - ETA: 0s - loss: 0.3169 - capsnet_loss: 0.3041 - decoder_loss: 0.0325 - capsnet_acc: 0.5514Epoch 00019: val_capsnet_acc improved from 0.55200 to 0.55700, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.3169 - capsnet_loss: 0.3042 - decoder_loss: 0.0325 - capsnet_acc: 0.5513 - val_loss: 0.3152 - val_capsnet_loss: 0.3025 - val_decoder_loss: 0.0324 - val_capsnet_acc: 0.5570
Epoch 20/50
499/500 [============================>.] - ETA: 0s - loss: 0.3154 - capsnet_loss: 0.3028 - decoder_loss: 0.0322 - capsnet_acc: 0.5551Epoch 00020: val_capsnet_acc improved from 0.55700 to 0.55890, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.3154 - capsnet_loss: 0.3028 - decoder_loss: 0.0322 - capsnet_acc: 0.5551 - val_loss: 0.3133 - val_capsnet_loss: 0.3007 - val_decoder_loss: 0.0320 - val_capsnet_acc: 0.5589
Epoch 21/50
500/500 [==============================] - 51s 101ms/step - loss: 0.3134 - capsnet_loss: 0.3009 - decoder_loss: 0.0319 - capsnet_acc: 0.5562 - val_loss: 0.3137 - val_capsnet_loss: 0.3011 - val_decoder_loss: 0.0320 - val_capsnet_acc: 0.5570
Epoch 22/50
499/500 [============================>.] - ETA: 0s - loss: 0.3104 - capsnet_loss: 0.2980 - decoder_loss: 0.0317 - capsnet_acc: 0.5603Epoch 00022: val_capsnet_acc improved from 0.55890 to 0.56060, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.3103 - capsnet_loss: 0.2979 - decoder_loss: 0.0317 - capsnet_acc: 0.5604 - val_loss: 0.3112 - val_capsnet_loss: 0.2987 - val_decoder_loss: 0.0319 - val_capsnet_acc: 0.5606
Epoch 23/50
499/500 [============================>.] - ETA: 0s - loss: 0.3106 - capsnet_loss: 0.2982 - decoder_loss: 0.0315 - capsnet_acc: 0.5613Epoch 00023: val_capsnet_acc improved from 0.56060 to 0.56570, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3106 - capsnet_loss: 0.2983 - decoder_loss: 0.0315 - capsnet_acc: 0.5613 - val_loss: 0.3100 - val_capsnet_loss: 0.2977 - val_decoder_loss: 0.0314 - val_capsnet_acc: 0.5657
Epoch 24/50
500/500 [==============================] - 51s 101ms/step - loss: 0.3082 - capsnet_loss: 0.2959 - decoder_loss: 0.0312 - capsnet_acc: 0.5646 - val_loss: 0.3097 - val_capsnet_loss: 0.2974 - val_decoder_loss: 0.0314 - val_capsnet_acc: 0.5635
Epoch 25/50
500/500 [==============================] - 51s 101ms/step - loss: 0.3070 - capsnet_loss: 0.2948 - decoder_loss: 0.0311 - capsnet_acc: 0.5661 - val_loss: 0.3100 - val_capsnet_loss: 0.2977 - val_decoder_loss: 0.0313 - val_capsnet_acc: 0.5638
Epoch 26/50
500/500 [==============================] - 51s 101ms/step - loss: 0.3053 - capsnet_loss: 0.2932 - decoder_loss: 0.0309 - capsnet_acc: 0.5714 - val_loss: 0.3088 - val_capsnet_loss: 0.2965 - val_decoder_loss: 0.0313 - val_capsnet_acc: 0.5655
Epoch 27/50
500/500 [==============================] - 51s 101ms/step - loss: 0.3047 - capsnet_loss: 0.2927 - decoder_loss: 0.0307 - capsnet_acc: 0.5701 - val_loss: 0.3077 - val_capsnet_loss: 0.2956 - val_decoder_loss: 0.0310 - val_capsnet_acc: 0.5632
Epoch 28/50
499/500 [============================>.] - ETA: 0s - loss: 0.3038 - capsnet_loss: 0.2918 - decoder_loss: 0.0306 - capsnet_acc: 0.5712Epoch 00028: val_capsnet_acc improved from 0.56570 to 0.56680, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3038 - capsnet_loss: 0.2918 - decoder_loss: 0.0306 - capsnet_acc: 0.5711 - val_loss: 0.3073 - val_capsnet_loss: 0.2952 - val_decoder_loss: 0.0308 - val_capsnet_acc: 0.5668
Epoch 29/50
499/500 [============================>.] - ETA: 0s - loss: 0.3024 - capsnet_loss: 0.2904 - decoder_loss: 0.0305 - capsnet_acc: 0.5746Epoch 00029: val_capsnet_acc improved from 0.56680 to 0.57040, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3024 - capsnet_loss: 0.2904 - decoder_loss: 0.0305 - capsnet_acc: 0.5746 - val_loss: 0.3060 - val_capsnet_loss: 0.2940 - val_decoder_loss: 0.0306 - val_capsnet_acc: 0.5704
Epoch 30/50
499/500 [============================>.] - ETA: 0s - loss: 0.3014 - capsnet_loss: 0.2895 - decoder_loss: 0.0304 - capsnet_acc: 0.5754Epoch 00030: val_capsnet_acc improved from 0.57040 to 0.57080, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.3015 - capsnet_loss: 0.2896 - decoder_loss: 0.0304 - capsnet_acc: 0.5754 - val_loss: 0.3057 - val_capsnet_loss: 0.2938 - val_decoder_loss: 0.0305 - val_capsnet_acc: 0.5708
Epoch 31/50
500/500 [==============================] - 51s 101ms/step - loss: 0.3012 - capsnet_loss: 0.2893 - decoder_loss: 0.0303 - capsnet_acc: 0.5751 - val_loss: 0.3061 - val_capsnet_loss: 0.2941 - val_decoder_loss: 0.0304 - val_capsnet_acc: 0.5682
Epoch 32/50
500/500 [==============================] - 51s 101ms/step - loss: 0.3003 - capsnet_loss: 0.2885 - decoder_loss: 0.0302 - capsnet_acc: 0.5794 - val_loss: 0.3054 - val_capsnet_loss: 0.2934 - val_decoder_loss: 0.0304 - val_capsnet_acc: 0.5700
Epoch 33/50
499/500 [============================>.] - ETA: 0s - loss: 0.2998 - capsnet_loss: 0.2880 - decoder_loss: 0.0301 - capsnet_acc: 0.5790Epoch 00033: val_capsnet_acc improved from 0.57080 to 0.57280, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.2997 - capsnet_loss: 0.2879 - decoder_loss: 0.0301 - capsnet_acc: 0.5790 - val_loss: 0.3045 - val_capsnet_loss: 0.2926 - val_decoder_loss: 0.0303 - val_capsnet_acc: 0.5728
Epoch 34/50
499/500 [============================>.] - ETA: 0s - loss: 0.2989 - capsnet_loss: 0.2871 - decoder_loss: 0.0300 - capsnet_acc: 0.5801Epoch 00034: val_capsnet_acc improved from 0.57280 to 0.57290, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.2988 - capsnet_loss: 0.2871 - decoder_loss: 0.0300 - capsnet_acc: 0.5802 - val_loss: 0.3041 - val_capsnet_loss: 0.2923 - val_decoder_loss: 0.0302 - val_capsnet_acc: 0.5729
Epoch 35/50
500/500 [==============================] - 51s 101ms/step - loss: 0.2983 - capsnet_loss: 0.2866 - decoder_loss: 0.0299 - capsnet_acc: 0.5818 - val_loss: 0.3043 - val_capsnet_loss: 0.2925 - val_decoder_loss: 0.0301 - val_capsnet_acc: 0.5700
Epoch 36/50
500/500 [==============================] - 51s 101ms/step - loss: 0.2972 - capsnet_loss: 0.2855 - decoder_loss: 0.0299 - capsnet_acc: 0.5830 - val_loss: 0.3043 - val_capsnet_loss: 0.2924 - val_decoder_loss: 0.0301 - val_capsnet_acc: 0.5724
Epoch 37/50
499/500 [============================>.] - ETA: 0s - loss: 0.2967 - capsnet_loss: 0.2850 - decoder_loss: 0.0299 - capsnet_acc: 0.5837Epoch 00037: val_capsnet_acc improved from 0.57290 to 0.57320, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.2967 - capsnet_loss: 0.2850 - decoder_loss: 0.0299 - capsnet_acc: 0.5837 - val_loss: 0.3036 - val_capsnet_loss: 0.2919 - val_decoder_loss: 0.0300 - val_capsnet_acc: 0.5732
Epoch 38/50
499/500 [============================>.] - ETA: 0s - loss: 0.2964 - capsnet_loss: 0.2847 - decoder_loss: 0.0298 - capsnet_acc: 0.5834Epoch 00038: val_capsnet_acc improved from 0.57320 to 0.57320, saving mode500/500 [==============================] - 51s 102ms/step - loss: 0.2963 - capsnet_loss: 0.2847 - decoder_loss: 0.0298 - capsnet_acc: 0.5835 - val_loss: 0.3035 - val_capsnet_loss: 0.2917 - val_decoder_loss: 0.0300 - val_capsnet_acc: 0.5732
Epoch 39/50
500/500 [==============================] - 51s 101ms/step - loss: 0.2970 - capsnet_loss: 0.2853 - decoder_loss: 0.0297 - capsnet_acc: 0.5820 - val_loss: 0.3034 - val_capsnet_loss: 0.2916 - val_decoder_loss: 0.0300 - val_capsnet_acc: 0.5715
Epoch 40/50
500/500 [==============================] - 50s 101ms/step - loss: 0.2964 - capsnet_loss: 0.2847 - decoder_loss: 0.0297 - capsnet_acc: 0.5837 - val_loss: 0.3035 - val_capsnet_loss: 0.2918 - val_decoder_loss: 0.0299 - val_capsnet_acc: 0.5720
Epoch 41/50
499/500 [============================>.] - ETA: 0s - loss: 0.2961 - capsnet_loss: 0.2845 - decoder_loss: 0.0297 - capsnet_acc: 0.5861Epoch 00041: val_capsnet_acc improved from 0.57320 to 0.57550, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.2960 - capsnet_loss: 0.2844 - decoder_loss: 0.0297 - capsnet_acc: 0.5863 - val_loss: 0.3030 - val_capsnet_loss: 0.2913 - val_decoder_loss: 0.0299 - val_capsnet_acc: 0.5755
Epoch 42/50
500/500 [==============================] - 51s 101ms/step - loss: 0.2952 - capsnet_loss: 0.2836 - decoder_loss: 0.0296 - capsnet_acc: 0.5865 - val_loss: 0.3030 - val_capsnet_loss: 0.2912 - val_decoder_loss: 0.0299 - val_capsnet_acc: 0.5742
Epoch 43/50
500/500 [==============================] - 51s 101ms/step - loss: 0.2954 - capsnet_loss: 0.2838 - decoder_loss: 0.0295 - capsnet_acc: 0.5859 - val_loss: 0.3031 - val_capsnet_loss: 0.2913 - val_decoder_loss: 0.0299 - val_capsnet_acc: 0.5730
Epoch 44/50
500/500 [==============================] - 51s 101ms/step - loss: 0.2952 - capsnet_loss: 0.2836 - decoder_loss: 0.0295 - capsnet_acc: 0.5847 - val_loss: 0.3028 - val_capsnet_loss: 0.2911 - val_decoder_loss: 0.0298 - val_capsnet_acc: 0.5730
Epoch 45/50
500/500 [==============================] - 51s 101ms/step - loss: 0.2958 - capsnet_loss: 0.2842 - decoder_loss: 0.0295 - capsnet_acc: 0.5859 - val_loss: 0.3027 - val_capsnet_loss: 0.2910 - val_decoder_loss: 0.0298 - val_capsnet_acc: 0.5741
Epoch 46/50
500/500 [==============================] - 51s 101ms/step - loss: 0.2956 - capsnet_loss: 0.2841 - decoder_loss: 0.0295 - capsnet_acc: 0.5839 - val_loss: 0.3028 - val_capsnet_loss: 0.2911 - val_decoder_loss: 0.0298 - val_capsnet_acc: 0.5727
Epoch 47/50
500/500 [==============================] - 51s 101ms/step - loss: 0.2956 - capsnet_loss: 0.2841 - decoder_loss: 0.0295 - capsnet_acc: 0.5840 - val_loss: 0.3026 - val_capsnet_loss: 0.2909 - val_decoder_loss: 0.0298 - val_capsnet_acc: 0.5753
Epoch 48/50
499/500 [============================>.] - ETA: 0s - loss: 0.2949 - capsnet_loss: 0.2834 - decoder_loss: 0.0294 - capsnet_acc: 0.5861Epoch 00048: val_capsnet_acc improved from 0.57550 to 0.57610, saving mode500/500 [==============================] - 51s 101ms/step - loss: 0.2950 - capsnet_loss: 0.2834 - decoder_loss: 0.0294 - capsnet_acc: 0.5860 - val_loss: 0.3026 - val_capsnet_loss: 0.2910 - val_decoder_loss: 0.0297 - val_capsnet_acc: 0.5761
Epoch 49/50
500/500 [==============================] - 51s 101ms/step - loss: 0.2949 - capsnet_loss: 0.2834 - decoder_loss: 0.0294 - capsnet_acc: 0.5865 - val_loss: 0.3024 - val_capsnet_loss: 0.2907 - val_decoder_loss: 0.0297 - val_capsnet_acc: 0.5749
Epoch 50/50
500/500 [==============================] - 50s 101ms/step - loss: 0.2950 - capsnet_loss: 0.2834 - decoder_loss: 0.0294 - capsnet_acc: 0.5867 - val_loss: 0.3025 - val_capsnet_loss: 0.2908 - val_decoder_loss: 0.0297 - val_capsnet_acc: 0.5747
Trained model saved to './result/trained_model.h5'
conranj@u-14:~/cifarcaps$ python capsulenet.py -t --digit 5 -w result/trained_model.h5
Using TensorFlow backend.
Namespace(batch_size=100, debug=False, digit=5, epochs=50, lam_recon=0.392, lr=0.001, lr_decay=1.0, routings=3, save_dir='./result', shift_fraction=0.1, testing=True, weights='result/trained_model.h5')
